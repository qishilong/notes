第 1-12 节，我们详细介绍了 ChatGPT 的模型建模结构、模型训练方式，以及训练数据的组织和特点。一方面，ChatGPT 颠覆了以往 NLP 这一领域的研究，对全社会产生了非常深远的影响；另一方面，ChatGPT 也存在一些不足之处，它还远未达到人工智能的终极形态。

这一节，我们主要介绍一下 ChatGPT 的优缺点，以及这个模型对当前社会、人类的生产生活产生了哪些影响。

  


# ChatGPT 优点

## ChatGPT 可以处理任何 NLP 领域任务

在 2022 年 11 月 30 日，ChatGPT 发布之前，市面上有大大小小的互联网或 IT 企业需要做自然语言处理。

绝大多数的 NLP 工程师们所做的工程项目，主要是针对某些特定任务提出一个具体的模型，进行有针对性的数据标注，然后再制作模型。简而言之，就是**以 NLP 子任务独立进行研究开发**。比如分词、实体识别、文本分类、相似度判别、机器翻译、文摘系统、事件抽取等等，不一而足。


![13-1.png](images/13-1.png-78.jpg)

  


> 例如，中英机器翻译模型就只能完成从中文翻译成英文这一项功能，若对机器翻译模型询问文本属于哪个类别？那就需要换一个文本分类模型了。
>
> 而如果想定制一个中文翻译为罗马尼亚语的模型，还需要标注大量的罗马尼亚语数据。其它 NLP 任务的模型也是同样的道理。

也就是说，NLP 产业界实际上处于一种传统的**手工业模式**，针对不同的企业、不同的需求，需要不断地定制模型和数据集来完成工作。每一个定制需求都需要人力，从而涌现出大量的 NLP 公司和从业者。

  


而 OpenAI 从 GPT2 开始就在研究多任务模型，目的是让 NLP 领域再也不区分各类不同的任务。这项任务至 ChatGPT 算是完全完成。用户可以向 AI 模型提出千奇百怪的问题，**ChatGPT 标志着 NLP 领域已经走过了手工业时代，正式进入了工业时代**。

  


实际上，ChatGPT 可以编写代码，做数学题，编写诗歌，这个模型的能力范围已经远远超过了过去的 NLP 领域局限的任务能力。正如第 12 节所介绍的，ChatGPT 已经不仅仅是一个针对自然语言的模型，它是一个基于文字模态的通用 AI 模型。

  


## ChatGPT 避免了超大规模的标注数据

  


AI 领域有句经典俗话，人工智能的含义就是，**有多少人工，就有多少智能**。这是说 AI 模型十分依赖标注数据，标注数据少，模型效果就弱，标注数据多且质量高，模型效果就好。

  


而 ChatGPT 模型制作过程中，主要是依赖大规模的**非标注数据**，至少上百 GB 的未经人工标注的高质量文本语料，却较少地依赖标注数据，在 RLHF 阶段，ChatGPT 仅仅使用了远少于预训练语料的数据，就完成了模型的训练。

  


自从 ChatGPT 发布以来，很多互联网科技公司都纷纷宣布制作对标 ChatGPT 的大语言模型（LLM）产品。很大程度上，这也得益于模型训练不再需要依赖超大规模的标注数据。当然，这并非指超大规模标注数据没有用，标注数据越多，模型质量越好，这是不变的法则。

  


# ChatGPT 缺点

## 幻觉妄语 Hallucination 严重

在第 12 节我们提到，ChatGPT 模型常常会编造一些信息，产生类似于精神病一样的幻觉妄语（Hallucination）回答。

  


例如`宫廷玉液酒`，我们都知道这是赵丽蓉老师的小品台词，用户输入“宫廷玉液酒”，其意图也是想和 ChatGPT 对暗号，看看能不能说出`一百八一杯`，用来测试到底是不是中国大陆的人。

![](images/image-79.jpg)

显然 ChatGPT 并没有理解这个对暗号的指示，而是把它当作一个概念解释进行展示了。这并不是真实存在的中国白酒，而是 ChatGPT 编造的虚假信息。这种虚假信息的编造，很可能是在模型预训练语料中，包含了中国其它白酒如茅台、五粮液、汾酒等酒品的介绍，因此模型能够根据这些素材进行二次创作，编造一些信息。

  


ChatGPT 无法完全分清楚**真实**和**虚构**。

  


再比如，ChatGPT 的回答产生了事实性的错误，误把计算机之父艾伦图灵当作电线的发明者。

![](images/image-80.jpg)

![](images/image-81.jpg)

而如果接着追问 ChatGPT，它又能给出正确的答案。这说明，模型训练过程中，语料确实包含了真实的、正确的信息的。但是在推理阶段，它还是犯错了。

ChatGPT 是一个依赖概率论构建的神经网络模型，它无可避免地会出现上述的错误。目前，OpenAI 已经推出了 GPT4 模型，效果比 ChatGPT 更上一层楼，Hallucination 发生概率更小。但即使它进化到 GPT4，它依然不是一个100% 稳妥可靠的知识库。因此，**ChatGPT 不可能完全替代掉** **搜索引擎**。例如以下例子：

![](images/image-82.jpg)

  


我大致可以推断出，在训练语料中，存在大量的 “`堂兄和堂妹可以结婚生子吗?`”这样类似的语料。对此，模型通过学习，会大致形成一种模式，即 “`亲属称谓1` `和` `亲属称谓2` `可以结婚生子吗?`”。回答答案当然是否定的。由此，ChatGPT 会把亲属称谓扩展引申至父亲和母亲，导致回答错误。

  


ChatGPT 本质上只是一个语言模型，它的核心目的，**是回答的内容像不像一个人类说的话，而非回答的内容是否真实可靠**。

  


实际上，人是不可以完全信任 AI 的。如果说，在过去，人类需要自己查找信息，自己判断信息的真伪，那么今后，AI 会替代人类查找信息，但**判断信息真伪始终需要人自己来完成**。换句话说，人类作为信息的终端，始终要自己为信息的真伪负责。


![13-2.png](images/13-2.png-83.jpg)

  


## ChatGPT 没有连接外部实时信息

ChatGPT 模型本身，无法回答一些实时性非常强的问题，它无法连接搜索引擎，获取信息，将最新的信息反馈给用户。

![](images/image-84.jpg)

这同样说明，ChatGPT 无法替代搜索引擎，反而更适合作为搜索引擎入口的一个非常好的优化。

  


这工作已经被微软的 **NewBing** 做了。其基本原理非常简单。首先将用户的问句输入搜索引擎中，搜索引擎会按照匹配程度，给出若干条搜索结果，然后，将用户的问句和搜索结果同时交给 ChatGPT，让它根据这份信息，做一个阅读理解，就可以回答实时性较高的问题啦。当然，微软 Bing 的做法在细节上肯定会丰富很多，比如，禁止回答用户的一些恶意问题等等。


![13-3.png](images/13-3.png-85.jpg)
  


除了微软的 Bing，OpenAI 也在网站中连接了互联网，方便实时信息的接入。

![](images/image-86.jpg)

  


## ChatGPT 本质上不具备思考和推理能力

  


如果让 ChatGPT 做一道数学题，它不仅仅会给出答案，还会给出解题过程。

![](images/image-87.jpg)

可能很多人看到都感觉惊讶，ChatGPT 已经具备了人的思考能力，推理能力。

  


然而实际上并非如此。根据前面第 1-12 节的介绍，ChatGPT 本质上是一个语言模型，通过大量的语料数据，拟合一个优质的模型效果。在上图中，ChatGPT 给出的所谓解答过程，实际上也出现在了模型预训练的语料当中。如果不出现在 ChatGPT 的预训练语料中的数学题，模型大概率是解答不出来的。

换句话说，当前的 AI 模型所表现出的各种推理能力，思考能力，仿佛它真的如人一般懂得了世界的运行逻辑。但实际上并非如此，ChatGPT 只是通过大量的数据学习，记住了题目的解答方式和解答过程。多向 ChatGPT 提问数学问题，就很容易看出这一点。

  


> 在中学读书阶段，常常有这样一类学生，他们不能深刻理解数学和物理背后的原理，而仅仅是从表面上背会了若干种题型，学会了套用公式，记住了若干概念文字。而如果题目条件变了，他们往往会被考住。
>
>   
>
>
> ChatGPT 的工作原理就很像这些学生。AI 模型是一个死记硬背的解题机器，而非能够融会贯通的独立的，能够创新思考的智能。只不过，ChatGPT 模型足够大，数据量足够多，它能够记忆远远超过人类的题目和题型，从而表现优秀。

  


因此，**ChatGPT 目前就是弱人工智能的顶峰，它距离强人工智能，还差不少距离**。

  


人的最核心能力是具有创造力，探索力，想象力。这些都是当前 AI 不具备的。ChatGPT 能够替科研人员写论文吗？显然是不能的，ChatGPT 只能帮助作者润色文字、语言和叙述逻辑，但核心的创新观点是目前 AI 无法做到的。

  


反过来，又有一个哲学问题，当 ChatGPT 继续进化，到 GPT4、GPT-n 时，即便模型依然不具备思考和推理能力，但它确实可以替代人完成很多工作，那么，AI 模型是否具备思考能力，还重要吗？

  


# ChatGPT 的影响

## ChatGPT 将侵占搜索引擎的市场份额

前面提到，ChatGPT 本身无法完全替代搜索引擎，很多信息还是需要用户自行到搜索引擎搜索结果，并判断哪些信息是可靠、有用的。

然而 ChatGPT 作为一个面向人类用户非常方便交流的接口途径，极大地优化了用户查询信息的使用体验。事实上，ChatGPT 已经挑战了搜索引擎的市场地位，Google 的搜索量统计指数逐渐下滑。

![](images/image-88.jpg)

## ChatGPT 将挑战当前的教育行业

一直以来，教育是每个文明国家、社会都非常重视的一项工作，对青少年的投资都标志着这个社会的活力和竞争力。

相信大家都接受过至少高中或大学以上教育。长达十多年的教育中，很多人都会发现，在高考前后是自己知识储备最全面，最充分的阶段。这说明，我们受教育过程当中，很大一部分内容都属于知识记忆，这部分知识，随着时间流逝，渐渐就被遗忘了；而那些知识当中蕴含的逻辑推理，人文欣赏，创新创造能力，则逐渐沉淀在大脑当中，形成一生的财富。

  


实际上，我们的教育中，单纯的知识记忆占了过大的比例，更有甚者，要求孩子背诵圆周率，这无疑是非常蠢的教育方式。ChatGPT 对这部分记忆知识点内容是最擅长的。任何客观知识点，询问 ChatGPT 都能够得到不错的答案，相反，逻辑推理，创新创造能力，则是 AI 模型目前不具备的。

  


所以，ChatGPT 的出现很可能对当前的教育行业进行洗牌，让教育更加注重**逻辑推理、人文欣赏、创新创造能力**。

  


## ChatGPT 带来的失业

ChatGPT 作为一个生产力工具，毫无疑问会造成一些岗位的消失和缩减。

  


首当其冲的就是 NLP 算法工程师和标注员。

制作一个 ChatGPT，不仅仅需要懂算法模型原理，同时还需要充分的算力和数据。没有这两样，优质的模型是无法制作出来的。OpenAI 每训练一次模型，就要耗费几十万美金，这样的成本代价，并非小公司、小机构能够负担得起。从各种新闻中，也可以感受到，有能力宣布制作对标 ChatGPT 模型产品的公司，都是国内外大型互联网公司，这是一个头部垄断的时代。在未来，不会需要那么多算法工程师和数据标注员。**ChatGPT 打开了 AI 行业垄断的大门**。

  


另一方面，如果真的想制作一个媲美 ChatGPT 的大模型，最简单直接获取数据的办法，就是向 ChatGPT 提问，直接把模型的问答当作数据集使用。

  


此外，任何与文字材料相关的工作都将受到冲击。

过去的新闻记者需要自己润色新闻稿，在未来就不再需要；电商客服需要人工对接买家的咨询，在未来也可以交给 AI；过去的笔译人员，在未来，也将急剧减少。自从 ChatGPT 出现以来，网络上出现了各种各样的基于 ChatGPT 的工具，它们可以帮助用户阅读论文，辅助写作，查询实时航班、车次，等等，**ChatGPT PLUS 还开放出了插件系统**，为各式各样的基于 AI 的功能扩展搭建了平台。种种迹象都表明，ChatGPT 正在改变整个社会的就业环境。

  


在中国社会的文化认知中，脑力劳动更符合大多数人的追求，从事体力劳动则会被认为不够体面。可事实上，ChatGPT 确确实实会减少脑力劳动岗位的数量。

  


  


# 总结

-   ChatGPT 跨越了过去 NLP 分任务的限制，极大程度减少了标注数据的限制，将 NLP 领域从手工业时代带入了NLP 工业时代。
-   ChatGPT 依然存在若干明显缺陷，幻觉妄语 Hallucination 情况时常发生，本质上不具备逻辑和推理能力，没有连接外部信息。
-   ChatGPT 带来的影响是深远的，它不仅仅是一个计算机实验室里的神经网络模型，而是一个 AI 改变世界的引子。